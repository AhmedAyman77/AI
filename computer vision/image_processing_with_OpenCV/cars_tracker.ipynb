{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280.0\n",
      "720.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QSocketNotifier: Can only be used with threads started with QThread\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('1.mp4')\n",
    "print(cap.get(3))\n",
    "print(cap.get(4))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D')\n",
    "# out = cv2.VideoWriter('output.avi', fourcc, 30.0, (1280,720))\n",
    "\n",
    "_, frame1 = cap.read()\n",
    "_, frame2 = cap.read()\n",
    "\n",
    "while cap.isOpened():\n",
    "    # get all changes that happened between two frames\n",
    "    diff = cv2.absdiff(frame1,frame2) # image segmentation\n",
    "    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    _, thresh = cv2.threshold(blur, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    dilation = cv2.dilate(thresh, None, iterations=10)\n",
    "\n",
    "    contours,_ = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # draw_contours = cv2.drawContours(frame1, contours, -1, (0,255,0), 2) # -1 means draw all contours   2 means thickness of the contour\n",
    "\n",
    "    for contour in contours:\n",
    "        (x,y,w,h) = cv2.boundingRect(contour)\n",
    "\n",
    "        if cv2.contourArea(contour) < 1000:\n",
    "            continue\n",
    "\n",
    "        cv2.rectangle(frame1, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "        cv2.putText(frame1, \"Status: Movement\", (10,20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 3)\n",
    "\n",
    "    img = cv2.resize(frame1, (1280,720))\n",
    "    # out.write(img)\n",
    "    cv2.imshow(\"feed\", frame1)\n",
    "    # cv2.imshow('diff',diff)\n",
    "    # cv2.imshow('gray',gray)\n",
    "    # cv2.imshow('blur', blur)\n",
    "    # cv2.imshow('thresh', thresh)\n",
    "    # cv2.imshow('dilation', dilation)\n",
    "\n",
    "    frame1 = frame2\n",
    "    _, frame2 = cap.read()\n",
    "\n",
    "    if cv2.waitKey(60) == 27: # wait 60 seconds before move to next frame\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "# out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>with counter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of cars -> 1\n",
      "num of cars -> 2\n",
      "num of cars -> 3\n",
      "num of cars -> 4\n",
      "num of cars -> 5\n"
     ]
    }
   ],
   "source": [
    "def get_center(x,y,w,h):\n",
    "    x1 = w//2\n",
    "    y1 = h//2\n",
    "    cx = x + x1\n",
    "    cy = y + y1\n",
    "    return cx,cy\n",
    "\n",
    "\n",
    "centers = []\n",
    "cars = 0\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture('1.mp4')\n",
    "\n",
    "# same as diff between frame1 and frame2\n",
    "BGS = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=100)\n",
    "\n",
    "while True:\n",
    "    _,frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    mask = BGS.apply(blur)\n",
    "    # img, kernel, iterations\n",
    "    dilation = cv2.dilate(mask, np.ones((3,3), np.uint8), iterations=3)\n",
    "\n",
    "    contours, _ = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    cv2.line(frame,(10, 450), (1280, 450), (255, 0, 0), 2)\n",
    "\n",
    "    for i,contour in enumerate(contours):\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        valid_contour = (w >= 80) and (h >= 80)\n",
    "        if not valid_contour:\n",
    "            continue\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        center = get_center(x, y, w, h)\n",
    "        centers.append(center)\n",
    "        cv2.circle(frame, center, 4, (0, 0, 255), -1)\n",
    "\n",
    "        for x,y in centers:\n",
    "            if y < (450+10) and y > (450-10):\n",
    "                cars += 1\n",
    "                cv2.line(frame,(10, 450), (1280, 450), (0, 255, 0), 2)\n",
    "                centers.remove((x,y))\n",
    "                print(f\"num of cars -> {cars}\")\n",
    "\n",
    "    cv2.putText(frame, \"cars -> \" + str(cars), (500, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 5)\n",
    "    cv2.imshow(\"video\", frame)\n",
    "    # cv2.imshow(\"mask\", mask)\n",
    "    # cv2.imshow(\"dilation\", dilation)\n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('./data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Object Detection</h1>\n",
    "<h4>Object Tracking Using HSV(Hue Saturation value) Color Space</h4>\n",
    "<p>HSV is useful for tracking an object in a picture or video and will be useful more than RGB</p>\n",
    "<h3>detect images</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QSocketNotifier: Can only be used with threads started with QThread\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "255\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "# Hue -> is the color\n",
    "# Saturation -> is the intensity of the color\n",
    "# Value -> is the brightness of the color\n",
    "\n",
    "def nothing(x):\n",
    "    print(x)\n",
    "\n",
    "cv2.namedWindow(\"Trackbars\")\n",
    "cv2.createTrackbar(\"L-H\", \"Trackbars\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"L-S\", \"Trackbars\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"L-V\", \"Trackbars\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"U-H\", \"Trackbars\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"U-S\", \"Trackbars\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"U-V\", \"Trackbars\", 255, 255, nothing)\n",
    "\n",
    "\n",
    "while True:\n",
    "    # change width and height of the pic\n",
    "    frame = cv2.imread('cat_375.jpg')\n",
    "    frame = cv2.resize(frame, (512, 512))\n",
    "    hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    lh = cv2.getTrackbarPos(\"L-H\", \"Trackbars\")\n",
    "    ls = cv2.getTrackbarPos(\"L-S\", \"Trackbars\")\n",
    "    lv = cv2.getTrackbarPos(\"L-V\", \"Trackbars\")\n",
    "    uh = cv2.getTrackbarPos(\"U-H\", \"Trackbars\")\n",
    "    us = cv2.getTrackbarPos(\"U-S\", \"Trackbars\")\n",
    "    uv = cv2.getTrackbarPos(\"U-V\", \"Trackbars\")\n",
    "\n",
    "    l_b = np.array([lh, ls, lv])\n",
    "    u_b = np.array([uh, us, uv])\n",
    "\n",
    "    mask = cv2.inRange(hsv, l_b, u_b)\n",
    "\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"res\", res)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>detect videos</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@14.236] global ./modules/videoio/src/cap_gstreamer.cpp (1405) open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "255\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "def nothing(x):\n",
    "    print(x)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow('Tracking')\n",
    "cv2.createTrackbar('LH',\"Tracking\",0,255,nothing)\n",
    "cv2.createTrackbar('LS',\"Tracking\",0,255,nothing)\n",
    "cv2.createTrackbar('LV',\"Tracking\",0,255,nothing)\n",
    "cv2.createTrackbar('UH',\"Tracking\",255,255,nothing)\n",
    "cv2.createTrackbar('US',\"Tracking\",255,255,nothing)\n",
    "cv2.createTrackbar('UV',\"Tracking\",255,255,nothing)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lh = cv2.getTrackbarPos('LH','Tracking')\n",
    "    ls = cv2.getTrackbarPos('LS','Tracking')\n",
    "    lv = cv2.getTrackbarPos('LV','Tracking')\n",
    "\n",
    "    uh = cv2.getTrackbarPos('UH','Tracking')\n",
    "    us = cv2.getTrackbarPos('US','Tracking')\n",
    "    uv = cv2.getTrackbarPos('UV','Tracking')\n",
    "\n",
    "    l_b = np.array([lh,ls,lv])\n",
    "    u_b = np.array([uh,us,uv])\n",
    "\n",
    "    mask = cv2.inRange(hsv, l_b, u_b)\n",
    "\n",
    "    res = cv2.bitwise_and(frame,frame,mask=mask)\n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Color Detection<h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@21.137] global ./modules/videoio/src/cap_gstreamer.cpp (1405) open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    height, width, _ = frame.shape\n",
    "    cx, cy = width//2,height//2\n",
    "\n",
    "    hsv_center = hsv[cx,cy]\n",
    "    Hue = hsv_center[0]\n",
    "\n",
    "    color = \"balck\"\n",
    "\n",
    "    if Hue < 5:\n",
    "        color = \"RED\"\n",
    "    elif Hue < 22:\n",
    "        color = \"ORANGE\"\n",
    "    elif Hue < 33:\n",
    "        color = \"YELLOW\"\n",
    "    elif Hue < 78:\n",
    "        color = \"GREEN\"\n",
    "    elif Hue < 131:\n",
    "        color = \"BLUE\"\n",
    "    elif Hue < 170:\n",
    "        color = \"VIOLET\"\n",
    "\n",
    "    BGR_center = frame[cx,cy]\n",
    "    b, g, r = int(BGR_center[0]), int(BGR_center[1]), int(BGR_center[2])\n",
    "\n",
    "    cv2.rectangle(frame, (cx-220,15), (cx+200,105),(255,255,255),-1)\n",
    "    cv2.putText(frame,color,(cx-220,100),0,3,(b,g,r),5)\n",
    "    cv2.circle(frame, (cx,cy),5,(255,255,255), 3)\n",
    "\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reinhard color transfer<h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mean_STD(x):\n",
    "    X_mean,X_std = cv2.meanStdDev(x)\n",
    "    X_mean = np.hstack(np.around(X_mean, 2))\n",
    "    X_std = np.hstack(np.around(X_std, 2))\n",
    "\n",
    "    return X_mean,X_std\n",
    "\n",
    "source_image = cv2.imread('428690.jpg')\n",
    "# convert to LAB\n",
    "source_image = cv2.cvtColor(source_image, cv2.COLOR_BGR2LAB)\n",
    "source_mean, source_STD = Mean_STD(source_image)\n",
    "\n",
    "target_image = cv2.imread(\"target.png\")\n",
    "target_image = cv2.cvtColor(target_image, cv2.COLOR_BGR2LAB)\n",
    "target_mean, target_std = Mean_STD(target_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(target_image.shape[0]):\n",
    "    for j in range(target_image.shape[1]):\n",
    "        l_target, a_target, b_target = target_image[i,j,0],target_image[i,j,1],target_image[i,j,2]\n",
    "\n",
    "        l = (source_STD[0]/target_std[0]) * (l_target-target_mean[0]) + source_mean[0]\n",
    "        a = (source_STD[1]/target_std[1]) * (a_target-target_mean[1]) + source_mean[1]\n",
    "        b = (source_STD[2]/target_std[2]) * (b_target-target_mean[2]) + source_mean[2]\n",
    "        \n",
    "        # clip the values to be in range [0,255]\n",
    "        target_image[i, j] = [np.clip(l, 0, 255), np.clip(a, 0, 255), np.clip(b, 0, 255)]\n",
    "\n",
    "output = cv2.cvtColor(target_image, cv2.COLOR_LAB2BGR)\n",
    "cv2.imshow(\"output\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

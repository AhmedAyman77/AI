{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>First Project Motion Detection</h1>\n",
    "<p>first step: movement is difference between two frames seconds<p>\n",
    "<p>second step: difference has noises because of details and light on video so Gaussian blurring is eliminating the noises</p>\n",
    "<p>third step: obtaining threshold from clean difference</p>\n",
    "<p>fourth step: dilating for eliminating district small weak threshold lines which corrupt healthy threshold detection</p>\n",
    "<p>fifth step: finding contours from clean threshold</p>\n",
    "<p>sixth step: eliminating small contours which cannot be a human by filtering contours area</p>\n",
    "<p>seventh step: drawing bounding box around contours</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "os.chdir('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QSocketNotifier: Can only be used with threads started with QThread\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('2.avi')\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 30.0, (1280,720))\n",
    "\n",
    "_, frame1 = cap.read()\n",
    "_, frame2 = cap.read()\n",
    "\n",
    "while cap.isOpened():\n",
    "    # get all changes that happened between two frames\n",
    "    diff = cv2.absdiff(frame1,frame2)\n",
    "    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    _, thresh = cv2.threshold(blur, 60, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    dilation = cv2.dilate(thresh, None, iterations=10)\n",
    "\n",
    "    contours,_ = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # draw_contours = cv2.drawContours(frame1, contours, -1, (0,255,0), 2) # -1 means draw all contours   2 means thickness of the contour\n",
    "\n",
    "    for contour in contours:\n",
    "        (x,y,w,h) = cv2.boundingRect(contour)\n",
    "\n",
    "        if cv2.contourArea(contour) < 1000:\n",
    "            continue\n",
    "\n",
    "        cv2.rectangle(frame1, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "        cv2.putText(frame1, \"Status: Movement\", (10,20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 3)\n",
    "\n",
    "    img = cv2.resize(frame1, (1280,720))\n",
    "    out.write(img)\n",
    "    cv2.imshow(\"feed\", frame1)\n",
    "    # cv2.imshow('diff',diff)\n",
    "    # cv2.imshow('gray',gray)\n",
    "    # cv2.imshow('blur', blur)\n",
    "    # cv2.imshow('thresh', thresh)\n",
    "    # cv2.imshow('dilation', dilation)\n",
    "\n",
    "    frame1 = frame2\n",
    "    _, frame2 = cap.read()\n",
    "\n",
    "    if cv2.waitKey(60) == 27: # wait 60 seconds before move to next frame\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izm9CE0WBpOe",
        "outputId": "3781e7e6-71e6-40ad-9b48-31bf13a178b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import torch\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from google.colab import drive\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "e6g7pCQcB2Qh"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "zYHKYVJzCThk"
      },
      "outputs": [],
      "source": [
        "train_data = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = MNIST(root='./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "ZwD_NFzhCiBl"
      },
      "outputs": [],
      "source": [
        "VALIDATION = 0.2\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "6rAhh4aqDA0i"
      },
      "outputs": [],
      "source": [
        "idx = np.arange(len(train_data))\n",
        "np.random.shuffle(idx)\n",
        "split = int(np.floor(VALIDATION * len(train_data)))\n",
        "train_idx, validation_idx = idx[split:], idx[:split]\n",
        "\n",
        "train_sample = torch.utils.data.sampler.SubsetRandomSampler(train_idx)\n",
        "validation_sample = torch.utils.data.sampler.SubsetRandomSampler(validation_idx)\n",
        "\n",
        "# when use sampler the shuffle is ignored\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=train_sample)\n",
        "validation_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=validation_sample)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_Or56mLEPfO",
        "outputId": "49f9f8dd-7ec5-4226-80be-9036f59c1989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "for data, target in train_loader:\n",
        "    print(data.shape, target.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijuklTpmEVwD"
      },
      "source": [
        "# nn.Sequential:\n",
        "Below we have defined the Deep Neural Network archietecture with the help of nn.Sequential."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "LPVPPkOnER5l"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(784, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "\n",
        "    nn.Linear(256, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "\n",
        "    nn.Linear(64, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "\n",
        "    nn.Linear(32, 10)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "nLXOnn6hFHzP"
      },
      "outputs": [],
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4blafxXpBRY"
      },
      "source": [
        "# GPU Support:\n",
        "First check that your GPU is working in Pytorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgW3N2pHpRAl",
        "outputId": "e53ab489-66d7-4f41-cd03-ce38e25680d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnXoD4klpVEH",
        "outputId": "754d412e-64f0-4ae2-95a1-4e380cb5c38d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\n",
        "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpvHMnqfpXQK",
        "outputId": "775a1d33-eb78-423e-82f4-74a70d317392"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Dropout(p=0.2, inplace=False)\n",
              "  (3): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (4): ReLU()\n",
              "  (5): Dropout(p=0.2, inplace=False)\n",
              "  (6): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (7): ReLU()\n",
              "  (8): Dropout(p=0.2, inplace=False)\n",
              "  (9): Linear(in_features=32, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mehcDcJwFVZp",
        "outputId": "f3929616-4551-4246-ca8f-601f4aa1a5c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 Training Loss:  0.24178626283506552\n",
            "Epoch: 1 Training Loss:  0.20305461174001296\n",
            "Epoch: 2 Training Loss:  0.18748830536256234\n",
            "Epoch: 3 Training Loss:  0.16939764230449994\n",
            "Epoch: 4 Training Loss:  0.15851584869995713\n",
            "Epoch: 5 Training Loss:  0.14813509132837255\n",
            "Epoch: 6 Training Loss:  0.14135003662109374\n",
            "Epoch: 7 Training Loss:  0.13241480752887824\n",
            "Epoch: 8 Training Loss:  0.13126647907868028\n",
            "Epoch: 9 Training Loss:  0.12394213820373019\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  train_loss, valid_loss = [], []\n",
        "\n",
        "  model.train()\n",
        "  for data, target in train_loader:\n",
        "\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    data = data.view(data.shape[0], -1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(data)\n",
        "\n",
        "    loss_value = loss(output, target)\n",
        "\n",
        "    loss_value.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss.append(loss_value.item())\n",
        "\n",
        "  print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjPdS6FzpnI8"
      },
      "source": [
        "# Save & Load The Model:\n",
        "As now the model has been trained , we will save the model and load again for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDWRZ4xfMXOw",
        "outputId": "e306fd95-6468-467c-a17e-52b6018b89dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "printing our model: \n",
            "\n",
            " Sequential(\n",
            "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Dropout(p=0.2, inplace=False)\n",
            "  (3): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): Dropout(p=0.2, inplace=False)\n",
            "  (6): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (7): ReLU()\n",
            "  (8): Dropout(p=0.2, inplace=False)\n",
            "  (9): Linear(in_features=32, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(\"printing our model: \\n\\n\", model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebR2gabCpyLY"
      },
      "source": [
        "To see the weights and biases of the model\n",
        "\n",
        "The parameters for PyTorch models are stored in a model's state_dict. state_dict containts the weights & biases of each of the layer , which can be accesed by state_dict().keys().\n",
        "\n",
        "Below we can see that , every layer's weight and biases have been printed out -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2dNxY1jpuzV",
        "outputId": "70b0bf74-d741-4e79-ac87-559d8ebc2582"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models layer keys: \n",
            "\n",
            " odict_keys(['0.weight', '0.bias', '3.weight', '3.bias', '6.weight', '6.bias', '9.weight', '9.bias'])\n"
          ]
        }
      ],
      "source": [
        "print(\"Models layer keys: \\n\\n\", model.state_dict().keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMFFXxjQsmkQ"
      },
      "source": [
        "# Weights and Bias Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeDCgQI9ski1",
        "outputId": "304e2e77-4c7a-43a3-edc2-6208c1b5dc46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.weight : tensor([[ 0.0349, -0.0043, -0.0057,  ...,  0.0188,  0.0100,  0.0073],\n",
            "        [-0.0158, -0.0011, -0.0023,  ..., -0.0206,  0.0304, -0.0233],\n",
            "        [-0.0259, -0.0173,  0.0187,  ...,  0.0158,  0.0196, -0.0012],\n",
            "        ...,\n",
            "        [ 0.0149,  0.0209,  0.0136,  ...,  0.0182,  0.0537,  0.0171],\n",
            "        [ 0.0120, -0.0070, -0.0152,  ...,  0.0267,  0.0261,  0.0423],\n",
            "        [ 0.0391,  0.0377,  0.0366,  ..., -0.0065,  0.0196,  0.0039]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "for params, values in model.state_dict().items():\n",
        "    print(params, \":\", values)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NP-n9aOsuRf"
      },
      "source": [
        "# Model's statedict can be saved using the **torch.save** which also accepts the models name as parameter as - model.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "DfAs_VwCspJd"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCWXMX9Fs92Y"
      },
      "source": [
        "# Saved model can also be loaded using the **torch.load()** using the saved model's path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mkRhgPps9kY",
        "outputId": "fa55fee4-f5bf-46f6-95e8-c8da7122833d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "odict_keys(['0.weight', '0.bias', '3.weight', '3.bias', '6.weight', '6.bias', '9.weight', '9.bias'])\n"
          ]
        }
      ],
      "source": [
        "state_dict = torch.load('model.pth')\n",
        "print(state_dict.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjsgbQ9MtuQ4"
      },
      "source": [
        "# To load the state dict in to the new model, you do **model.load_state_dict(state_dict)**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMd1jT0atMSj",
        "outputId": "3527488b-060d-4278-b81e-bb6d436125b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSdaWJnpt2wk"
      },
      "source": [
        "# **Important Note**: Loading the state dict will work only if the new model architecture is exactly the same as the saved's model's architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7298hWN_uM-I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

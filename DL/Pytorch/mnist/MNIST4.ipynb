{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izm9CE0WBpOe",
        "outputId": "3781e7e6-71e6-40ad-9b48-31bf13a178b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import torch\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from google.colab import drive\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "e6g7pCQcB2Qh"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "zYHKYVJzCThk"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION = 0.2\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "ZwD_NFzhCiBl"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.arange(len(train_data))\n",
        "np.random.shuffle(idx)\n",
        "split = int(np.floor(VALIDATION * len(train_data)))\n",
        "train_idx, validation_idx = idx[split:], idx[:split]\n",
        "\n",
        "train_sample = torch.utils.data.sampler.SubsetRandomSampler(train_idx)\n",
        "validation_sample = torch.utils.data.sampler.SubsetRandomSampler(validation_idx)\n",
        "\n",
        "# when use sampler the shuffle is ignored\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=train_sample)\n",
        "validation_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=validation_sample)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "6rAhh4aqDA0i"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data, target in train_loader:\n",
        "    print(data.shape, target.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_Or56mLEPfO",
        "outputId": "49f9f8dd-7ec5-4226-80be-9036f59c1989"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Normalization:\n",
        "Added Batch Normalization after the linear but before the non linear activation function"
      ],
      "metadata": {
        "id": "ijuklTpmEVwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(784, 256)\n",
        "    self.bn1 = nn.BatchNorm1d(256)\n",
        "\n",
        "    self.fc2 = nn.Linear(256, 64)\n",
        "    self.bn2 = nn.BatchNorm1d(64)\n",
        "\n",
        "    self.fc3 = nn.Linear(64, 32)\n",
        "    self.bn3 = nn.BatchNorm1d(32)\n",
        "\n",
        "    self.fc4 = nn.Linear(32, 10)\n",
        "\n",
        "    self.Droupout = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = self.Droupout(F.relu(self.bn1(self.fc1(x))))\n",
        "    x = self.Droupout(F.relu(self.bn2(self.fc2(x))))\n",
        "    x = self.Droupout(F.relu(self.bn3(self.fc3(x))))\n",
        "\n",
        "    x = self.fc4(x)\n",
        "    return x\n",
        "\n",
        "model = Model()"
      ],
      "metadata": {
        "id": "LPVPPkOnER5l"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "nLXOnn6hFHzP"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Rate Scheduler:\n",
        "Here we will use the StepLR i.e. Step Learning Rate scheduler. Below is the reference and example from Pytorch doc:\n",
        "\n",
        "- torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=0.1, last_epoch=-1)\n",
        "Sets the learning rate of each parameter group to the initial lr decayed by gamma every step_size epochs.\n",
        "\n",
        "Parameters:\n",
        "\n",
        "optimizer (Optimizer) – Wrapped optimizer.\n",
        "step_size (int) – Period of learning rate decay.\n",
        "gamma (float) – Multiplicative factor of learning rate decay. Default: 0.1.\n",
        "last_epoch (int) – The index of last epoch. Default: -1.\n",
        "Example: scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "Assuming optimizer uses lr = 0.05 for all groups\n",
        "lr = 0.05 if epoch < 5\n",
        "lr = 0.005 if 5 <= epoch < 10\n",
        "lr = 0.0005 if 10 <= epoch < 15\n",
        "Examples describes that the initial learning rate defined in the optimizer step was 0.05 , which will be reducuded after every 5 epochs.Learning Rate will be decreased with the multiplication factor of 0.1(i.e. the value defined in gamma).\n",
        "\n"
      ],
      "metadata": {
        "id": "x4blafxXpBRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)"
      ],
      "metadata": {
        "id": "h9dFLX2Yy5mk"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgW3N2pHpRAl",
        "outputId": "1d90d5a2-4703-44e3-b7fe-41b3d6ace2f6"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\n",
        "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnXoD4klpVEH",
        "outputId": "580892fa-d6fc-4e97-cd68-6b11889556d7"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpvHMnqfpXQK",
        "outputId": "8851b163-0800-4dc2-b31d-e65d08efeaa8"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc4): Linear(in_features=32, out_features=10, bias=True)\n",
              "  (Droupout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  train_loss, valid_loss = [], []\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "  for data, target in train_loader:\n",
        "\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    data = data.view(data.shape[0], -1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(data)\n",
        "\n",
        "    loss_value = loss(output, target)\n",
        "\n",
        "    loss_value.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss.append(loss_value.item())\n",
        "\n",
        "  print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mehcDcJwFVZp",
        "outputId": "586c3271-e265-44e6-8403-dad6ee81d249"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Training Loss:  0.06910441623752316\n",
            "Epoch: 1 Training Loss:  0.07150576159668466\n",
            "Epoch: 2 Training Loss:  0.06944089407784243\n",
            "Epoch: 3 Training Loss:  0.0692833774096022\n",
            "Epoch: 4 Training Loss:  0.07216225838040312\n",
            "Epoch: 5 Training Loss:  0.07104084116530915\n",
            "Epoch: 6 Training Loss:  0.07223497697214286\n",
            "Epoch: 7 Training Loss:  0.07058095913007856\n",
            "Epoch: 8 Training Loss:  0.07066613508760929\n",
            "Epoch: 9 Training Loss:  0.07002611597379049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qeWsJrE70Or7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izm9CE0WBpOe",
        "outputId": "278d2d0b-31a9-4c65-e4cd-30a49f6a34b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import torch\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from google.colab import drive\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of subprocesses to use for data loading\n",
        "NUM_WORKERS = 1\n",
        "BATCH_SIZE =  10\n",
        "EPOCHS = 10\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_data = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILOjIVswj3AD",
        "outputId": "8853654a-951f-483e-9dd7-8ef091d882f7"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch, label_batch = next(iter(train_loader))\n",
        "image_batch.shape, label_batch.shape"
      ],
      "metadata": {
        "id": "e6g7pCQcB2Qh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a867a1e-8c7c-43a5-e509-9c360200f3fa"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10, 3, 32, 32]), torch.Size([10]))"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output volume can be calculated with below formula:\n",
        "\n",
        "- Input: n X n X nc\n",
        "- Filter: f X f X nc\n",
        "- Padding: p\n",
        "- Stride: s\n",
        "- Output: [((n+2p-f)/s)+1] X [((n+2p-f)/s)+1] X nc’ (height X width X no of output channels)\n",
        "nc is the number of channels in the input and filter, while nc’ is the number of filters.\n",
        "\n",
        "From the above structure you can see that height/width is getting reduced and number of channels are getting incresed.\n",
        "\n",
        "Example calulating the output of first convolution + pooling layer operation -\n",
        "\n",
        "Input image shape - 32(n) X 32(n) X 3(nc)\n",
        "\n",
        "# 1. ConVNet filter operation - self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True)\n",
        "\n",
        "Filter shape - 3 (f) X 3 (f) X 3(nc) Padding : P = 1 Stride : s = 1 (default value) output channels - 16 (kernel_size)\n",
        "\n",
        "putting it in the formula given above -\n",
        "\n",
        "[((n+2p-f)/s)+1] X [((n+2p-f)/s)+1] X nc’\n",
        "\n",
        "[((32 + 2X1 - 3) / 1) + 1)] X [((32 + 2X1 - 3) / 1)) + 1)] X 16\n",
        "\n",
        "output shape -> 32 X 32 X 16\n",
        "\n",
        "# 2. output of conv1 is passed through max pooling layer.\n",
        "self.pool = nn.MaxPool2d(2, 2) -> filter of 2 X 2.\n",
        "\n",
        "this will shrink the height & width by half , however no of channels will remain same.\n",
        "\n",
        "input to the pooling layer - 32 X 32 X 16\n",
        "\n",
        "output of the pooing layer - 32/2 X 32/2 X 16 -> 16 X 16 X 16"
      ],
      "metadata": {
        "id": "oenGyk-qtkej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
        "    self.fc2 = nn.Linear(500, 10)\n",
        "    self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.pool(F.relu(self.conv3(x)))\n",
        "\n",
        "    x = x.view(-1, 64 * 4 * 4)\n",
        "\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "model = Model()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "LPVPPkOnER5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d81ba7c-f009-4dc4-a486-b1dd26743d37"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
            "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "nLXOnn6hFHzP"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)"
      ],
      "metadata": {
        "id": "h9dFLX2Yy5mk"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgW3N2pHpRAl",
        "outputId": "26c698ab-6373-413d-c073-daa5c305abdd"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\n",
        "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnXoD4klpVEH",
        "outputId": "c03e91f5-783d-4849-fe60-780c0c265a25"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpvHMnqfpXQK",
        "outputId": "8fe0b2fd-b026-41da-d812-6e8b9ce2ace1"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
              "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  train_loss = []\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "  for i,(data, target) in enumerate(train_loader):\n",
        "\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(data)\n",
        "\n",
        "    loss_value = loss(output, target)\n",
        "\n",
        "    loss_value.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 2000 == 0:\n",
        "      print (f'Epoch {epoch+1}, Step {i+1}, Loss: {loss_value.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mehcDcJwFVZp",
        "outputId": "63eec170-1e37-4757-e1e7-1989ce64b64d"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Step 2000, Loss: 0.9437\n",
            "Epoch 1, Step 4000, Loss: 0.8935\n",
            "Epoch 2, Step 2000, Loss: 1.2074\n",
            "Epoch 2, Step 4000, Loss: 1.1237\n",
            "Epoch 3, Step 2000, Loss: 0.8088\n",
            "Epoch 3, Step 4000, Loss: 0.9106\n",
            "Epoch 4, Step 2000, Loss: 0.8739\n",
            "Epoch 4, Step 4000, Loss: 0.4180\n",
            "Epoch 5, Step 2000, Loss: 0.9002\n",
            "Epoch 5, Step 4000, Loss: 1.4210\n",
            "Epoch 6, Step 2000, Loss: 0.5169\n",
            "Epoch 6, Step 4000, Loss: 0.5073\n",
            "Epoch 7, Step 2000, Loss: 0.6669\n",
            "Epoch 7, Step 4000, Loss: 0.3486\n",
            "Epoch 8, Step 2000, Loss: 0.7935\n",
            "Epoch 8, Step 4000, Loss: 0.9906\n",
            "Epoch 9, Step 2000, Loss: 0.7701\n",
            "Epoch 9, Step 4000, Loss: 0.5769\n",
            "Epoch 10, Step 2000, Loss: 1.6942\n",
            "Epoch 10, Step 4000, Loss: 0.3762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for data, target in test_loader:\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    output = model(data)\n",
        "    _, pred = torch.max(output.data, 1)\n",
        "    total += target.size(0)\n",
        "    correct += (pred == target).sum().item()\n",
        "\n",
        "  print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "qeWsJrE70Or7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "381ea686-732b-4a40-fd9c-a2f1787e7302"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 69 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "trwXkqlxscAE"
      },
      "execution_count": 102,
      "outputs": []
    }
  ]
}